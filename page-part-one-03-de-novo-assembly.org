#+Title: De novo assembly - Complete workflow
#+Summary: Assembly
#+URL: part-one-03-de-novo-assembly.html
#+Save_as: part-one-03-de-novo-assembly.html
#+Status: hidden
#+OPTIONS: toc:3 num:nil html-postamble:nil

* /De novo/ assembly

@@html:<div class="navLink">@@[[file:part-one-02-raw-reads-processing.html][Previous: Raw reads processing]]@@html:</div>@@

** Assembly into consensus sequences

We choose to go for a /de novo/ assembly since we do not have a genome for this
species. Several tools were tested, and in the end we decided to go with a bit
older tool, CAP3 ([[http://www.ncbi.nlm.nih.gov/pmc/articles/PMC310812/][original publication]]), which can incorporate quality
information in the assembly process.

We perform two independent assemblies, one for the forward reads and one for
the reverse reads.

*** Concatenate all reads for a given sense

We have to pool all the reads of a given sense together:
#+BEGIN_SRC bash
ls -1
#+END_SRC
#+BEGIN_SRC
ABB.pair.for.fastq.clean
ABB.pair.rev.fastq.clean
BYN.pair.for.fastq.clean
BYN.pair.rev.fastq.clean
HKI.pair.for.fastq.clean
HKI.pair.rev.fastq.clean
LEV.pair.for.fastq.clean
LEV.pair.rev.fastq.clean
POR.pair.for.fastq.clean
POR.pair.rev.fastq.clean
PYO.pair.for.fastq.clean
PYO.pair.rev.fastq.clean
RYT.pair.for.fastq.clean
RYT.pair.rev.fastq.clean
SKA.pair.for.fastq.clean
SKA.pair.rev.fastq.clean
#+END_SRC
#+BEGIN_SRC bash
cat *for* > for.fastq
cat *rev* > rev.fastq
#+END_SRC

We obtain two large files with all the reads.

*** TODO Run CAP3 (forward reads)

CAP3 takes for input two files, one containing the FASTA sequences and one
containing the corresponding quality scores. We can split the FASTQ files into
those two files using a [[file:resources/split_fasta_qual.py][python script]] (=split_fasta_qual.py=):
#+BEGIN_SRC bash
python split_fasta_qual.py for.fastq
python split_fasta_qual.py rev.fastq
#+END_SRC

We submit the CAP3 assembly as a job on the ABiMS server. We need to prepare
our [[file:resources/cap3-for-job][job file]] (=cap3-for-job=) (see the ABiMS [[http://abims.sb-roscoff.fr/resources/cluster/howto][how-to]] page for more details about
job files and how to submit them):
#+BEGIN_SRC bash
#!/bin/bash
#$ -S /bin/bash
#$ -M matthieu.bruneaux@ens-lyon.org
#$ -V
#$ -m bea
#$ -cwd
cap3 for.fastq.fasta > for.cap3.log
#+END_SRC
Here the command is simply =cap3 for.fastq.fasta > for.cap3.log=. CAP3
automatically gets the quality information from =for.fastq.fasta.qual=.

The job file is submitted to the long queue with:
#+BEGIN_SRC bash
qsub -q long.q cap3-for-job
#+END_SRC

*** TODO Run CAP3 (reverse reads)

Submit a similar assembly for the reverse reads.

An alternative approach would have been to map the reads back to the reference
genome. Why did we not use the threespine genome as a reference? 

(When mapping back we have to be quite stringent and allow only for example one
or two mismatch, and one unique good quality mapping location. With the
reference genome of a different species, this can be problematic and the
mapping back might be less efficient that creating consensus contigs or
stacks.)

*** CAP3 run

The CAP3 run is quite long (a bit more than 15 hours for the reverse reads). We
give you the assembly for the reverse reads (=CAP3-rev.fasta=), using the
default parameters of CAP3. Note that for a real analysis we would need to made
several tests with different parameters and select the ones that give the
better assembly.

** Quality filtering of consensus sequences

The /de novo/ assembly with CAP3 can be tuned by changing the parameters from
the default ones (which we should do for a real analysis). An assembly is
likely not to be perfect and the resulting consensus sequences have to be
quality checked before being used for read mapping.

*** TODO Examine read length

Because of the ddRAD protocol, we expect to produce consensus sequences by
piling up identical or very similar reads into stacks. Since most of the reads
have the same length to start with (xx for forward reads and xx for reverse
reads after cutting the barcode and restriction sites), we expect to obtain
consensus sequences of the same length.

We can get the length of the reads by using a homemade [[file:resources/get_read_length.py][python script]]
(=get_fasta_length.py=):
#+BEGIN_SRC bash
python get_fasta_length.py cap3-rev.fasta
#+END_SRC
We can plot the read length distribution with R:
#+BEGIN_SRC R
# R script
#
# Plot read length distribution
#------------------------------

d = read.table("cap3-rev.fasta.lengths")
plot(hist(d[, 1])
#+END_SRC

How does the length distribution look like? How would you remove the sequences
that do not match the median length?

*** TODO Identify repetitive motives or extremely similar consensus sequences

CAP3 sometimes produces consensus which contain repetitive motives or very
similar consensus sequences. Those sequences are problematic for the read
mapping back. We perform a blast of the consensus sequences against themselves
to identify sequences which have motives with many matches, or duplicate
consensus sequences.

To perform the blast search, we firt prepare a blast database from the
consensus sequences and then we use =blastn=:
#+BEGIN_SRC bash
# Prepare the blast database
makeblastdb -help
makeblastdb -in cap3-rev.fasta -dbtype nucl
#+END_SRC

We have to perform the =blastn= by submitting a job because it is a long
process. See =blastn -help= for more details. The job file is
=cap3-blastn-job=:
#+BEGIN_SRC 
#!/bin/bash
#$ -S /bin/bash
#$ -M matthieu.bruneaux@ens-lyon.org
#$ -V
#$ -m bea
#$ -cwd
# Perform the blast search (output in tabular format)
blastn -task blastn -db cap3-rev.fasta -query cap3-rev.fasta -out cap3-blastn-results -outfmt 6
#+END_SRC

We submit the job with =qsub -q long.q cap3-for-job=. Here we ask for a tabular
output format.

Next, we parse the results to identify consensus sequences to be removed or to
be merged together. We must remember that the default output for =blastn= in
tabular format is (from =blastn -help=):
#+BEGIN_SRC 
qseqid sseqid pident length mismatch gapopen qstart qend sstart send evalue bitscore
#+END_SRC
We can first have a look at the distribution of the size of the matches;
#+BEGIN_SRC bash
cut -f 4 cap3-blastn-results > lengths
#+END_SRC
#+BEGIN_SRC R
# R script
d = read.table("lengths")[, 1]
hist(d)
#+END_SRC

What threshold would you use to consider a match to be important based on this
distribution? How you would keep only the matches longer than this threshold in
the blastn result file?

We can also look at the number of matches for each consensus sequence:
#+BEGIN_SRC 
cut -f 1 cap3-blastn-results > seq-names
sort seq-names > seq-names-sorted
uniq -c seq-names-sorted > seq-names-count
sort -nr seq-names-count > seq-match-count
#+END_SRC
#+BEGIN_SRC R
# R script
d = read.table("seq-match-count")
plot(d[, 1])
#+END_SRC

How does the distribution of matches look like? How would you select a
threshold? How would you apply it?

*** TODO Remove microsatellite repeats

The last quality control step is to remove consensus sequences that contains
microsatellite repeats. To do this, we use Sputnik on the consensus
sequences. We should use it on the consensus sequence file after removing the
sequences with repeated motives, but since the intermediate file is missing
we'll run it on the full consensus file. We have to submit a job again,
=sputnik-job=:
#+BEGIN_SRC 
#!/bin/bash
#$ -S /bin/bash
#$ -M matthieu.bruneaux@ens-lyon.org
#$ -V
#$ -m bea
#$ -cwd
# Perform the blast search (output in tabular format)
sputnik cap3-rev.fasta
#+END_SRC

We submit it with =qsub -q long.q sputnik-job=.

Examine the output of Sputnik and count the number of contigs with
microsatellite repeats. How would you proceed to remove them from the initial
consensus file?

@@html:<div class="navLink">@@[[file:part-one-04-variant-calling-genotyping.html][Next: Variant calling and genotyping]]@@html:</div>@@
